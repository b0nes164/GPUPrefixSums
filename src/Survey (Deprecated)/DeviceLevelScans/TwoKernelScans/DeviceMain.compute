/******************************************************************************
 * Device Main 
 * 
 * Scan:    Warp-Sized-Radix Raking Reduce then Scan
 *
 * Variant: A single reduction kernel using Brent-Kung on threadblock aggregates,
 *          followed by a second kernel where the aggregrates are passed into a warp-sized
 *          radix reduce scan.
 *          
 * Note:    Max threadblocks is 1024 in this implementation, because of the scan used
 *          on the spine of the reduction.
 *
 *          **Preprocessor macros must be manually changed for AMD**
 *
 * Author:  Thomas Smith 5/8/2023
 *
 * License: The Unlicense
 *          This is free and unencumbered software released into the public domain.
 *          For more information, please refer to the repository license or <https://unlicense.org>
 *
 ******************************************************************************/
#pragma use_dxc
#pragma kernel Init
#pragma kernel DeviceMainReduce
#pragma kernel DeviceMainScan
#pragma kernel DeviceMainReduceTiming
#pragma kernel DeviceMainScanTiming

#define SUB_PARTITION_SIZE      8192
#define SUB_PARTITION_MASK      8191
#define SUB_PART_LOG            13

#define GROUP_SIZE              1024
#define THREAD_BLOCKS           256
#define TBLOCK_LOG              8

#define LANE_COUNT              32  // <---------------------------   For Nvidia; change depending on hardware
#define LANE_MASK               31
#define LANE_LOG                5
#define WAVES_PER_GROUP         32
#define WAVE_PARTITION_SIZE     256
#define WAVE_PART_LOG           8

//#define LANE_COUNT            64 <-------------------------   AMD 
//#define LANE_MASK             63
//#define LANE_LOG              6    
//#define WAVES_PER_GROUP       16
//#define WAVE_PARTITION_SIZE   512
//#define WAVE_PART_LOG         9

#define LANE                (gtid.x & LANE_MASK)
#define WAVE_INDEX          (gtid.x >> LANE_LOG)
#define SPINE_INDEX         (((gtid.x + 1) << WAVE_PART_LOG) - 1)
#define WAVE_PART_START     (WAVE_INDEX << WAVE_PART_LOG)
#define WAVE_PART_END       (WAVE_INDEX + 1 << WAVE_PART_LOG)
#define PARTITION_SIZE      (e_size >> TBLOCK_LOG)
#define PARTITION_START     (gid.x * PARTITION_SIZE)
#define SUB_PART_START      (subPartitionIndex << SUB_PART_LOG)
#define SUB_PARTITIONS      ((PARTITION_SIZE & SUB_PARTITION_MASK) ? \
                            (PARTITION_SIZE >> SUB_PART_LOG) + 1 :   \
                            PARTITION_SIZE >> SUB_PART_LOG )
#define EXACT_SUB_SIZE      (PARTITION_SIZE - SUB_PART_START)
#define FINAL_PART_SIZE     (e_size - PARTITION_START)
#define FINAL_SUB_PARTS     ((FINAL_PART_SIZE & SUB_PARTITION_MASK) ? \
                            (FINAL_PART_SIZE >> SUB_PART_LOG) + 1 :   \
                            FINAL_PART_SIZE >> SUB_PART_LOG )
#define FINAL_SUB_SIZE      (FINAL_PART_SIZE -  SUB_PART_START)

//Adjusted partition indexes for timing kernel
#define T_PART_INDEX        (g & 255)       //For 256 THREAD_BLOCKS ONLY
#define T_PART_START        (T_PART_INDEX * PARTITION_SIZE)
#define T_FINAL_PART_SIZE   (e_size - T_PART_START)
#define T_FINAL_SUB_PARTS   ((T_FINAL_PART_SIZE & SUB_PARTITION_MASK) ? \
                            (T_FINAL_PART_SIZE >> SUB_PART_LOG) + 1 :   \
                            T_FINAL_PART_SIZE >> SUB_PART_LOG )
#define T_FINAL_SUB_SIZE    (T_FINAL_PART_SIZE - SUB_PART_START)


extern int e_size;
extern int e_repeats;

RWBuffer<uint> b_prefixSum;
globallycoherent RWBuffer<uint> b_state;
groupshared uint g_sharedMem[SUB_PARTITION_SIZE];

[numthreads(GROUP_SIZE, 1, 1)]
void Init(int3 id : SV_DispatchThreadID)
{
    for (int i = id.x; i < e_size; i += GROUP_SIZE * THREAD_BLOCKS)
        b_prefixSum[i] = 1;
}

[numthreads(GROUP_SIZE, 1, 1)]
void DeviceMainReduce(int3 gtid : SV_GroupThreadID, int3 gid : SV_GroupID)
{
    uint waveAggregate = 0;
    const int partitionEnd = gid.x == THREAD_BLOCKS - 1 ? e_size : (gid.x + 1) * PARTITION_SIZE;
    for (int j = gtid.x + PARTITION_START; j < partitionEnd; j += GROUP_SIZE)
        waveAggregate += WaveActiveSum(b_prefixSum[j]);
    GroupMemoryBarrierWithGroupSync();
    
    if (LANE == 0)
        g_sharedMem[WAVE_INDEX] = waveAggregate;
    GroupMemoryBarrierWithGroupSync();
    
    if (gtid.x < WAVES_PER_GROUP)
        g_sharedMem[gtid.x] = WaveActiveSum(g_sharedMem[gtid.x]);
    
    if (gtid.x == 0)
    {
        InterlockedAdd(b_state[gid.x], g_sharedMem[gtid.x]);
        InterlockedAdd(b_state[THREAD_BLOCKS], 1, g_sharedMem[0]);
    }
    GroupMemoryBarrierWithGroupSync();
    
    if (WaveReadLaneFirst(g_sharedMem[0]) == THREAD_BLOCKS - 1)
    {
        GroupMemoryBarrierWithGroupSync();
        if (gtid.x < THREAD_BLOCKS)
        {
            g_sharedMem[gtid.x] = b_state[gtid.x];
            g_sharedMem[gtid.x] += WavePrefixSum(g_sharedMem[gtid.x]);
        }
        GroupMemoryBarrierWithGroupSync();
        
        if (gtid.x < (THREAD_BLOCKS >> LANE_LOG))
            g_sharedMem[((gtid.x + 1) << LANE_LOG) - 1] += WavePrefixSum(g_sharedMem[((gtid.x + 1) << LANE_LOG) - 1]);
        GroupMemoryBarrierWithGroupSync();
        
        if (gtid.x < THREAD_BLOCKS)
            b_state[gtid.x] = g_sharedMem[gtid.x] +
                (LANE < LANE_MASK && gtid.x > LANE_MASK ? WaveReadLaneFirst(g_sharedMem[gtid.x - 1]) : 0);
    }
}

[numthreads(GROUP_SIZE, 1, 1)]
void DeviceMainScan(int3 gtid : SV_GroupThreadID, uint3 gid : SV_GroupID)
{
    uint aggregate = gid.x ? b_state[gid.x - 1] : 0;
    if (gid.x == THREAD_BLOCKS - 1)
    {
        for (int subPartitionIndex = 0; subPartitionIndex < FINAL_SUB_PARTS - 1; ++subPartitionIndex)
        {
            g_sharedMem[LANE + WAVE_PART_START] = b_prefixSum[LANE + WAVE_PART_START + SUB_PART_START + PARTITION_START];
            g_sharedMem[LANE + WAVE_PART_START] += WavePrefixSum(g_sharedMem[LANE + WAVE_PART_START]);
        
            [unroll(7)]
            for (int i = LANE + WAVE_PART_START + LANE_COUNT; i < WAVE_PART_END; i += LANE_COUNT)
            {
                g_sharedMem[i] = b_prefixSum[i + SUB_PART_START + PARTITION_START];
                g_sharedMem[i] += WavePrefixSum(g_sharedMem[i]) + WaveReadLaneFirst(g_sharedMem[i - 1]);
            }
            GroupMemoryBarrierWithGroupSync();
        
            if (gtid.x < WAVES_PER_GROUP)
                g_sharedMem[SPINE_INDEX] += WavePrefixSum(g_sharedMem[SPINE_INDEX]);
            GroupMemoryBarrierWithGroupSync();
        
            const uint prev = (WAVE_INDEX ? WaveReadLaneFirst(g_sharedMem[WAVE_PART_START - 1]) : 0) + aggregate;
            [unroll(8)]
            for (int i = LANE + WAVE_PART_START; i < WAVE_PART_END; i += LANE_COUNT)
                b_prefixSum[i + SUB_PART_START + PARTITION_START] = g_sharedMem[i] + (i < WAVE_PART_END - 1 ? prev : aggregate);
        
            aggregate += WaveReadLaneFirst(g_sharedMem[SUB_PARTITION_MASK]);
            GroupMemoryBarrierWithGroupSync();
        }
    
        int wavePartEnd = WAVE_PART_END;
        if (wavePartEnd > FINAL_SUB_SIZE)
            wavePartEnd = (FINAL_SUB_SIZE - 1 >> WAVE_PART_LOG) == WAVE_INDEX ? FINAL_SUB_SIZE : 0;
    
        if (LANE < (wavePartEnd - WAVE_PART_START))
        {
            g_sharedMem[LANE + WAVE_PART_START] = b_prefixSum[LANE + WAVE_PART_START + SUB_PART_START + PARTITION_START];
            g_sharedMem[LANE + WAVE_PART_START] += WavePrefixSum(g_sharedMem[LANE + WAVE_PART_START]);
        }
        for (int i = LANE + WAVE_PART_START + LANE_COUNT; i < wavePartEnd; i += LANE_COUNT)
        {
            g_sharedMem[i] = b_prefixSum[i + SUB_PART_START + PARTITION_START];
            g_sharedMem[i] += WavePrefixSum(g_sharedMem[i]) + WaveReadLaneFirst(g_sharedMem[i - 1]);
        }
        GroupMemoryBarrierWithGroupSync();
        
        if (gtid.x < WAVES_PER_GROUP)
        {
            int t = SPINE_INDEX;
            if (t > FINAL_SUB_SIZE - 1)
                t = (FINAL_SUB_SIZE - 1 >> WAVE_PART_LOG) == gtid.x ? FINAL_SUB_SIZE - 1 : SUB_PARTITION_SIZE - gtid.x;
            g_sharedMem[t] += WavePrefixSum(g_sharedMem[t]) + aggregate;
        }
        GroupMemoryBarrierWithGroupSync();
        
        const uint prev = (WAVE_INDEX ? WaveReadLaneFirst(g_sharedMem[WAVE_PART_START - 1]) : aggregate);
        for (int i = LANE + WAVE_PART_START; i < wavePartEnd; i += LANE_COUNT)
            b_prefixSum[i + SUB_PART_START + PARTITION_START] = g_sharedMem[i] + (i < wavePartEnd - 1 ? prev : 0);
    }
    else
    {
        for (int subPartitionIndex = 0; subPartitionIndex < SUB_PARTITIONS - 1; ++subPartitionIndex)
        {
            g_sharedMem[LANE + WAVE_PART_START] = b_prefixSum[LANE + WAVE_PART_START + SUB_PART_START + PARTITION_START];
            g_sharedMem[LANE + WAVE_PART_START] += WavePrefixSum(g_sharedMem[LANE + WAVE_PART_START]);
        
            [unroll(7)]
            for (int i = LANE + WAVE_PART_START + LANE_COUNT; i < WAVE_PART_END; i += LANE_COUNT)
            {
                g_sharedMem[i] = b_prefixSum[i + SUB_PART_START + PARTITION_START];
                g_sharedMem[i] += WavePrefixSum(g_sharedMem[i]) + WaveReadLaneFirst(g_sharedMem[i - 1]);
            }
            GroupMemoryBarrierWithGroupSync();
        
            if (gtid.x < WAVES_PER_GROUP)
                g_sharedMem[SPINE_INDEX] += WavePrefixSum(g_sharedMem[SPINE_INDEX]);
            GroupMemoryBarrierWithGroupSync();
        
            const uint prev = (WAVE_INDEX ? WaveReadLaneFirst(g_sharedMem[WAVE_PART_START - 1]) : 0) + aggregate;
            [unroll(8)]
            for (int i = LANE + WAVE_PART_START; i < WAVE_PART_END; i += LANE_COUNT)
                b_prefixSum[i + SUB_PART_START + PARTITION_START] = g_sharedMem[i] + (i < WAVE_PART_END - 1 ? prev : aggregate);
        
            aggregate += WaveReadLaneFirst(g_sharedMem[SUB_PARTITION_MASK]);
            GroupMemoryBarrierWithGroupSync();
        }
    
        int wavePartEnd = WAVE_PART_END;
        if (wavePartEnd > EXACT_SUB_SIZE)
            wavePartEnd = (EXACT_SUB_SIZE - 1 >> WAVE_PART_LOG) == WAVE_INDEX ? EXACT_SUB_SIZE : 0;
    
        if (LANE < (wavePartEnd - WAVE_PART_START))
        {
            g_sharedMem[LANE + WAVE_PART_START] = b_prefixSum[LANE + WAVE_PART_START + SUB_PART_START + PARTITION_START];
            g_sharedMem[LANE + WAVE_PART_START] += WavePrefixSum(g_sharedMem[LANE + WAVE_PART_START]);
        }
        for (int i = LANE + WAVE_PART_START + LANE_COUNT; i < wavePartEnd; i += LANE_COUNT)
        {
            g_sharedMem[i] = b_prefixSum[i + SUB_PART_START + PARTITION_START];
            g_sharedMem[i] += WavePrefixSum(g_sharedMem[i]) + WaveReadLaneFirst(g_sharedMem[i - 1]);
        }
        GroupMemoryBarrierWithGroupSync();
        
        if (gtid.x < WAVES_PER_GROUP)
        {
            int t = SPINE_INDEX;
            if (t > EXACT_SUB_SIZE - 1)
                t = (EXACT_SUB_SIZE - 1 >> WAVE_PART_LOG) == gtid.x ? EXACT_SUB_SIZE - 1 : SUB_PARTITION_SIZE - gtid.x;
            g_sharedMem[t] += WavePrefixSum(g_sharedMem[t]) + aggregate;
        }
        GroupMemoryBarrierWithGroupSync();
        
        const uint prev = (WAVE_INDEX ? WaveReadLaneFirst(g_sharedMem[WAVE_PART_START - 1]) : aggregate);
        for (int i = LANE + WAVE_PART_START; i < wavePartEnd; i += LANE_COUNT)
            b_prefixSum[i + SUB_PART_START + PARTITION_START] = g_sharedMem[i] + (i < wavePartEnd - 1 ? prev : 0);
    }
}

/******************************************************************************
 * This is timing version of the scan. It is as similar as possible to the above
 * algorithm except that it can perform multiple loops. HOWEVER, IT IS NOT IDENTICAL,
 * and should only be interpreted as an approximation of the original algorithm. 
 ******************************************************************************/
[numthreads(GROUP_SIZE, 1, 1)]
void DeviceMainReduceTiming(int3 gtid : SV_GroupThreadID, int3 gid : SV_GroupID)
{
    for(int g = gid.x; g < (e_repeats << TBLOCK_LOG); g += THREAD_BLOCKS)
    {
        uint waveAggregate = 0;
        const int partitionEnd = T_PART_INDEX == THREAD_BLOCKS - 1 ? e_size : (T_PART_INDEX + 1) * PARTITION_SIZE;
        for (int j = gtid.x + T_PART_START; j < partitionEnd; j += GROUP_SIZE)
            waveAggregate += WaveActiveSum(b_prefixSum[j]);
        GroupMemoryBarrierWithGroupSync();
    
        if (LANE == 0)
            g_sharedMem[WAVE_INDEX] = waveAggregate;
        GroupMemoryBarrierWithGroupSync();
    
        if (gtid.x < WAVES_PER_GROUP)
            g_sharedMem[gtid.x] = WaveActiveSum(g_sharedMem[gtid.x]);
    
        if (gtid.x == 0)
        {
            InterlockedAdd(b_state[g], g_sharedMem[gtid.x]);
            InterlockedAdd(b_state[e_repeats << TBLOCK_LOG], 1, g_sharedMem[0]);
        }
        GroupMemoryBarrierWithGroupSync();
    
        if ((WaveReadLaneFirst(g_sharedMem[0]) & THREAD_BLOCKS - 1) == THREAD_BLOCKS - 1)
        {
            GroupMemoryBarrierWithGroupSync();
            if (gtid.x < THREAD_BLOCKS)
            {
                g_sharedMem[gtid.x] = b_state[gtid.x];
                g_sharedMem[gtid.x] += WavePrefixSum(g_sharedMem[gtid.x + ((g >> TBLOCK_LOG) << TBLOCK_LOG)]);
            }
            GroupMemoryBarrierWithGroupSync();
        
            if (gtid.x < (THREAD_BLOCKS >> LANE_LOG))
                g_sharedMem[((gtid.x + 1) << LANE_LOG) - 1] += WavePrefixSum(g_sharedMem[((gtid.x + 1) << LANE_LOG) - 1]);
            GroupMemoryBarrierWithGroupSync();
        
            if (gtid.x < THREAD_BLOCKS)
                b_state[gtid.x + ((g >> TBLOCK_LOG) << TBLOCK_LOG)] = g_sharedMem[gtid.x] +
                    (LANE < LANE_MASK && gtid.x > LANE_MASK ? WaveReadLaneFirst(g_sharedMem[gtid.x - 1]) : 0);
        }
    }
}

[numthreads(GROUP_SIZE, 1, 1)]
void DeviceMainScanTiming(int3 gtid : SV_GroupThreadID, int3 gid : SV_GroupID)
{
    for (int g = gid.x; g < (e_repeats << TBLOCK_LOG); g += THREAD_BLOCKS)
    {
        uint aggregate = T_PART_INDEX ? b_state[g - 1] : 0;
        if (T_PART_INDEX == THREAD_BLOCKS - 1)
        {
            for (int subPartitionIndex = 0; subPartitionIndex < T_FINAL_SUB_PARTS - 1; ++subPartitionIndex)
            {
                g_sharedMem[LANE + WAVE_PART_START] = b_prefixSum[LANE + WAVE_PART_START + SUB_PART_START + T_PART_START];
                g_sharedMem[LANE + WAVE_PART_START] += WavePrefixSum(g_sharedMem[LANE + WAVE_PART_START]);
        
                [unroll(7)]
                for (int i = LANE + WAVE_PART_START + LANE_COUNT; i < WAVE_PART_END; i += LANE_COUNT)
                {
                    g_sharedMem[i] = b_prefixSum[i + SUB_PART_START + T_PART_START];
                    g_sharedMem[i] += WavePrefixSum(g_sharedMem[i]) + WaveReadLaneFirst(g_sharedMem[i - 1]);
                }
                GroupMemoryBarrierWithGroupSync();
        
                if (gtid.x < WAVES_PER_GROUP)
                    g_sharedMem[SPINE_INDEX] += WavePrefixSum(g_sharedMem[SPINE_INDEX]);
                GroupMemoryBarrierWithGroupSync();
        
                const uint prev = (WAVE_INDEX ? WaveReadLaneFirst(g_sharedMem[WAVE_PART_START - 1]) : 0) + aggregate;
                [unroll(8)]
                for (int i = LANE + WAVE_PART_START; i < WAVE_PART_END; i += LANE_COUNT)
                    b_prefixSum[i + SUB_PART_START + T_PART_START] = g_sharedMem[i] + (i < WAVE_PART_END - 1 ? prev : aggregate);
        
                aggregate += WaveReadLaneFirst(g_sharedMem[SUB_PARTITION_MASK]);
                GroupMemoryBarrierWithGroupSync();
            }
    
            int wavePartEnd = WAVE_PART_END;
            if (wavePartEnd > T_FINAL_SUB_SIZE)
                wavePartEnd = (T_FINAL_SUB_SIZE - 1 >> WAVE_PART_LOG) == WAVE_INDEX ? T_FINAL_SUB_SIZE : 0;
    
            if (LANE < (wavePartEnd - WAVE_PART_START))
            {
                g_sharedMem[LANE + WAVE_PART_START] = b_prefixSum[LANE + WAVE_PART_START + SUB_PART_START + T_PART_START];
                g_sharedMem[LANE + WAVE_PART_START] += WavePrefixSum(g_sharedMem[LANE + WAVE_PART_START]);
            }
            for (int i = LANE + WAVE_PART_START + LANE_COUNT; i < wavePartEnd; i += LANE_COUNT)
            {
                g_sharedMem[i] = b_prefixSum[i + SUB_PART_START + T_PART_START];
                g_sharedMem[i] += WavePrefixSum(g_sharedMem[i]) + WaveReadLaneFirst(g_sharedMem[i - 1]);
            }
            GroupMemoryBarrierWithGroupSync();
        
            if (gtid.x < WAVES_PER_GROUP)
            {
                int t = SPINE_INDEX;
                if (t > T_FINAL_SUB_SIZE - 1)
                    t = (T_FINAL_SUB_SIZE - 1 >> WAVE_PART_LOG) == gtid.x ? T_FINAL_SUB_SIZE - 1 : SUB_PARTITION_SIZE - gtid.x;
                g_sharedMem[t] += WavePrefixSum(g_sharedMem[t]) + aggregate;
            }
            GroupMemoryBarrierWithGroupSync();
        
            const uint prev = (WAVE_INDEX ? WaveReadLaneFirst(g_sharedMem[WAVE_PART_START - 1]) : aggregate);
            for (int i = LANE + WAVE_PART_START; i < wavePartEnd; i += LANE_COUNT)
                b_prefixSum[i + SUB_PART_START + T_PART_START] = g_sharedMem[i] + (i < wavePartEnd - 1 ? prev : 0);
        }
        else
        {
            for (int subPartitionIndex = 0; subPartitionIndex < SUB_PARTITIONS - 1; ++subPartitionIndex)
            {
                g_sharedMem[LANE + WAVE_PART_START] = b_prefixSum[LANE + WAVE_PART_START + SUB_PART_START + T_PART_START];
                g_sharedMem[LANE + WAVE_PART_START] += WavePrefixSum(g_sharedMem[LANE + WAVE_PART_START]);
        
                [unroll(7)]
                for (int i = LANE + WAVE_PART_START + LANE_COUNT; i < WAVE_PART_END; i += LANE_COUNT)
                {
                    g_sharedMem[i] = b_prefixSum[i + SUB_PART_START + T_PART_START];
                    g_sharedMem[i] += WavePrefixSum(g_sharedMem[i]) + WaveReadLaneFirst(g_sharedMem[i - 1]);
                }
                GroupMemoryBarrierWithGroupSync();
        
                if (gtid.x < WAVES_PER_GROUP)
                    g_sharedMem[SPINE_INDEX] += WavePrefixSum(g_sharedMem[SPINE_INDEX]);
                GroupMemoryBarrierWithGroupSync();
        
                const uint prev = (WAVE_INDEX ? WaveReadLaneFirst(g_sharedMem[WAVE_PART_START - 1]) : 0) + aggregate;
                [unroll(8)]
                for (int i = LANE + WAVE_PART_START; i < WAVE_PART_END; i += LANE_COUNT)
                    b_prefixSum[i + SUB_PART_START + T_PART_START] = g_sharedMem[i] + (i < WAVE_PART_END - 1 ? prev : aggregate);
        
                aggregate += WaveReadLaneFirst(g_sharedMem[SUB_PARTITION_MASK]);
                GroupMemoryBarrierWithGroupSync();
            }
    
            int wavePartEnd = WAVE_PART_END;
            if (wavePartEnd > EXACT_SUB_SIZE)
                wavePartEnd = (EXACT_SUB_SIZE - 1 >> WAVE_PART_LOG) == WAVE_INDEX ? EXACT_SUB_SIZE : 0;
    
            if (LANE < (wavePartEnd - WAVE_PART_START))
            {
                g_sharedMem[LANE + WAVE_PART_START] = b_prefixSum[LANE + WAVE_PART_START + SUB_PART_START + T_PART_START];
                g_sharedMem[LANE + WAVE_PART_START] += WavePrefixSum(g_sharedMem[LANE + WAVE_PART_START]);
            }
            for (int i = LANE + WAVE_PART_START + LANE_COUNT; i < wavePartEnd; i += LANE_COUNT)
            {
                g_sharedMem[i] = b_prefixSum[i + SUB_PART_START + T_PART_START];
                g_sharedMem[i] += WavePrefixSum(g_sharedMem[i]) + WaveReadLaneFirst(g_sharedMem[i - 1]);
            }
            GroupMemoryBarrierWithGroupSync();
        
            if (gtid.x < WAVES_PER_GROUP)
            {
                int t = SPINE_INDEX;
                if (t > EXACT_SUB_SIZE - 1)
                    t = (EXACT_SUB_SIZE - 1 >> WAVE_PART_LOG) == gtid.x ? EXACT_SUB_SIZE - 1 : SUB_PARTITION_SIZE - gtid.x;
                g_sharedMem[t] += WavePrefixSum(g_sharedMem[t]) + aggregate;
            }
            GroupMemoryBarrierWithGroupSync();
        
            const uint prev = (WAVE_INDEX ? WaveReadLaneFirst(g_sharedMem[WAVE_PART_START - 1]) : aggregate);
            for (int i = LANE + WAVE_PART_START; i < wavePartEnd; i += LANE_COUNT)
                b_prefixSum[i + SUB_PART_START + T_PART_START] = g_sharedMem[i] + (i < wavePartEnd - 1 ? prev : 0);
        }
    }
}