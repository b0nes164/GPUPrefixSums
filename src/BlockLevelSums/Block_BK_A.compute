/******************************************************************************
 * Block Level Warp-Sized Radix Brent Kung using shared memory.
 * 
 * Variant: Partition size equal to the square of the wave size.
 *          Shared memory size equal to the partition size.
 * 
 * Notes: **Unrolls and preprocessor macros must be manually changed for AMD**
 *
 * Author:  Thomas Smith 5/9/2023
 *
 * License: The Unlicense
 *          This is free and unencumbered software released into the public domain.
 *          For more information, please refer to the repository license or <https://unlicense.org>
 *
 ******************************************************************************/
#pragma use_dxc
#pragma kernel Init
#pragma kernel Block_BK_A
#pragma kernel Block_BK_A_Timing

#define GROUP_SIZE      1024

#define PARTITION_SIZE  1024        //<---------------------------   For Nvidia; change depending on hardware
#define PARTITION_MASK  1023
#define PART_LOG        10
#define LANE_COUNT      32  
#define LANE_MASK       31
#define LANE_LOG        5

//#define PARTITION_SIZE    4096    <----------------------------   AMD 
//#define PARTITION_MASK    4095
//#define PART_LOG          12
//#define LANE_COUNT        64 
//#define LANE_MASK         63
//#define LANE_LOG          6    

extern int e_size;
extern int e_repeats;

#define PARTITIONS          ((e_size & PARTITION_MASK) ? \
                            (e_size >> PART_LOG) + 1 : \
                            e_size >> PART_LOG)
#define PARTITION_START     (partitionIndex << PART_LOG)
#define WAVES_PER_GROUP     (GROUP_SIZE >> LANE_LOG)
#define SPINE_INDEX         (((gtid.x + 1) << LANE_LOG) - 1)
#define EXACT_SIZE          (e_size - (partitionIndex << PART_LOG))

RWBuffer<uint> b_prefixSum;
groupshared uint g_sharedMem[PARTITION_SIZE];

[numthreads(GROUP_SIZE, 1, 1)]
void Init(int3 id : SV_DispatchThreadID)
{
    for (int i = id.x; i < e_size; i += (GROUP_SIZE << 8))
        b_prefixSum[i] = 1;
}

[numthreads(GROUP_SIZE, 1, 1)]
void Block_BK_A(int3 gtid : SV_GroupThreadID)
{
    uint aggregate = 0;
    for (int partitionIndex = 0; partitionIndex < PARTITIONS - 1; ++partitionIndex)
    {
        for (int i = gtid.x; i < PARTITION_SIZE; i += GROUP_SIZE)
        {
            g_sharedMem[i] = b_prefixSum[i + PARTITION_START];
            g_sharedMem[i] += WavePrefixSum(g_sharedMem[i]);
        }
        GroupMemoryBarrierWithGroupSync();
        
        if (gtid.x < WAVES_PER_GROUP)
            g_sharedMem[SPINE_INDEX] += WavePrefixSum(g_sharedMem[SPINE_INDEX]) + aggregate;
        GroupMemoryBarrierWithGroupSync();

        for (i = gtid.x; i < PARTITION_SIZE; i += GROUP_SIZE)
        {
            b_prefixSum[i + PARTITION_START] = g_sharedMem[i] +
                ((i + 1 & LANE_MASK) ? ((i >> LANE_LOG) ? WaveReadLaneFirst(g_sharedMem[i - 1]) : aggregate) : 0);
        }
        
        aggregate = WaveReadLaneFirst(g_sharedMem[PARTITION_SIZE - 1]);
        GroupMemoryBarrierWithGroupSync();
    }
    
    for (int i = gtid.x; i < EXACT_SIZE; i += GROUP_SIZE)
    {
        g_sharedMem[i] = b_prefixSum[i + PARTITION_START];
        g_sharedMem[i] += WavePrefixSum(g_sharedMem[i]);
    }
    GroupMemoryBarrierWithGroupSync();
        
    if (gtid.x < (EXACT_SIZE >> LANE_LOG))
        g_sharedMem[SPINE_INDEX] += WavePrefixSum(g_sharedMem[SPINE_INDEX]) + aggregate;
    GroupMemoryBarrierWithGroupSync();

    for (int i = gtid.x; i < EXACT_SIZE; i += GROUP_SIZE)
    {
        b_prefixSum[i + PARTITION_START] = g_sharedMem[i] +
                ((i + 1 & LANE_MASK) ? ((i >> LANE_LOG) ? WaveReadLaneFirst(g_sharedMem[i - 1]) : aggregate) : 0);
    }
}

/******************************************************************************
 * This is timing version of the scan. It is as similar as possible to the above
 * algorithm except that it can perform multiple loops. HOWEVER, IT IS NOT IDENTICAL,
 * and should only be interpreted as an approximation of the original algorithm. 
 ******************************************************************************/
[numthreads(GROUP_SIZE, 1, 1)]
void Block_BK_A_Timing(int3 gtid : SV_GroupThreadID)
{
    for (int g = 0; g < e_repeats; ++g)
    {
        uint aggregate = 0;
        for (int partitionIndex = 0; partitionIndex < PARTITIONS - 1; ++partitionIndex)
        {
            for (int i = gtid.x; i < PARTITION_SIZE; i += GROUP_SIZE)
            {
                g_sharedMem[i] = b_prefixSum[i + PARTITION_START];
                g_sharedMem[i] += WavePrefixSum(g_sharedMem[i]);
            }
            GroupMemoryBarrierWithGroupSync();
        
            if (gtid.x < WAVES_PER_GROUP)
                g_sharedMem[SPINE_INDEX] += WavePrefixSum(g_sharedMem[SPINE_INDEX]) + aggregate;
            GroupMemoryBarrierWithGroupSync();

            for (i = gtid.x; i < PARTITION_SIZE; i += GROUP_SIZE)
            {
                b_prefixSum[i + PARTITION_START] = g_sharedMem[i] +
                    ((i + 1 & LANE_MASK) ? ((i >> LANE_LOG) ? WaveReadLaneFirst(g_sharedMem[i - 1]) : aggregate) : 0);
            }
        
            aggregate = WaveReadLaneFirst(g_sharedMem[PARTITION_SIZE - 1]);
            GroupMemoryBarrierWithGroupSync();
        }
    
        for (int i = gtid.x; i < EXACT_SIZE; i += GROUP_SIZE)
        {
            g_sharedMem[i] = b_prefixSum[i + PARTITION_START];
            g_sharedMem[i] += WavePrefixSum(g_sharedMem[i]);
        }
        GroupMemoryBarrierWithGroupSync();
        
        if (gtid.x < (EXACT_SIZE >> LANE_LOG))
            g_sharedMem[SPINE_INDEX] += WavePrefixSum(g_sharedMem[SPINE_INDEX]) + aggregate;
        GroupMemoryBarrierWithGroupSync();

        for (int i = gtid.x; i < EXACT_SIZE; i += GROUP_SIZE)
        {
            b_prefixSum[i + PARTITION_START] = g_sharedMem[i] +
                ((i + 1 & LANE_MASK) ? ((i >> LANE_LOG) ? WaveReadLaneFirst(g_sharedMem[i - 1]) : aggregate) : 0);
        }
    }
}